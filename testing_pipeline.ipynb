{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0, 1 and 2 are to develop and test the different steps of the pipeline. \n",
    "\n",
    "Later, you only need to (pre-)train the bbox and segmentation models directly from the terminal (see README.md). \n",
    "\n",
    "Once you have those two models you can start simulating/testing the Challenge inference and evaluation pipeline.\n",
    "For that, go directly to step 3 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1 Load and define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper_code import *\n",
    "from team_code import *\n",
    "\n",
    "print(f\"DEVICE: {DEVICE}\")\n",
    "print(f\"WORLD_SIZE: {WORLD_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "data_training_path = f\"{ROOT}/data/ptb-xl/Dataset{X_FREQUENCY}_Signals/imagesTr_original\"\n",
    "data_vali_path = f\"{ROOT}/data/ptb-xl/Dataset{X_FREQUENCY}_Signals/imagesTv_original\"\n",
    "data_test_path = f\"{ROOT}/data/ptb-xl/Dataset{X_FREQUENCY}_Signals/imagesTs_original\"\n",
    "data_output_path = \"data/\"\n",
    "model_folder = \"model/\"\n",
    "model_folder_checkpoints = \"model/checkpoints/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2 Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "records, data, loader = dataloader_wrapper(\n",
    "    list_of_paths=[data_training_path, data_vali_path, data_test_path],\n",
    "    test_settings=[False, False, True],\n",
    "    shuffle_settings=[True, False, False],\n",
    "    transform=None,\n",
    "    single_signals=False,\n",
    "    run_in_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the mask. It should not have a border and only two kind of values (0 and 1)\n",
    "mask = data[1][0][\"mask\"]\n",
    "print(data[1][0][\"info_dict\"][\"image_path\"])\n",
    "print(mask.shape)\n",
    "print(mask[0])\n",
    "print(pd.Series(mask[0].flatten()).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show test_images with test_masks on top\n",
    "inspection_plots(loader_to_use=loader[1], num_images_to_plot=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Total image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Test rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "records, data, loader = dataloader_wrapper(\n",
    "    list_of_paths=[data_training_path, data_vali_path, data_test_path],\n",
    "    test_settings=[False, False, True],\n",
    "    shuffle_settings=[True, False, False],\n",
    "    transform=None,\n",
    "    run_in_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted rotation angles\n",
    "rot_angle_list = {}\n",
    "for batch_idx, batch_dicts in enumerate(loader[1]):\n",
    "    for j in range(len(batch_dicts[\"image\"])):\n",
    "        image = batch_dicts[\"image_original\"][j].permute(1, 2, 0)\n",
    "        image = image.numpy().astype(np.uint8)\n",
    "        lines = get_lines(image, threshold_HoughLines=1200)\n",
    "        filtered_lines = filter_lines(\n",
    "            lines, degree_window=30, parallelism_count=3, parallelism_window=2\n",
    "        )\n",
    "        if filtered_lines is None:\n",
    "            rot_angle = np.nan\n",
    "        else:\n",
    "            rot_angle = get_median_degrees(filtered_lines)\n",
    "        rot_angle_list[batch_dicts[\"info_dict\"][\"image_path\"][j]] = {\n",
    "            \"rot_angle_predicted\": rot_angle,\n",
    "            \"rot_angle_predicted_loader\": np.float64(\n",
    "                batch_dicts[\"info_dict\"][\"rot_angle_predicted\"][j].numpy()\n",
    "            ),\n",
    "            \"actual_rotation\": batch_dicts[\"info_dict\"][\"rotation\"][j],\n",
    "            \"image\": image,\n",
    "            \"lines\": lines,\n",
    "            \"filtered_lines\": filtered_lines,\n",
    "        }\n",
    "\n",
    "# Compare if loader and step wise prediction are the same\n",
    "predicted_as_loader = sum(\n",
    "    [\n",
    "        1\n",
    "        for k, v in rot_angle_list.items()\n",
    "        if (v[\"rot_angle_predicted\"] == v[\"rot_angle_predicted_loader\"])\n",
    "        or (\n",
    "            np.isnan(v[\"rot_angle_predicted\"])\n",
    "            and np.isnan(v[\"rot_angle_predicted_loader\"])\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(f\"Same as loader: {predicted_as_loader} out of {len(rot_angle_list)}\")\n",
    "for k, v in rot_angle_list.items():\n",
    "    if (v[\"rot_angle_predicted\"] != v[\"rot_angle_predicted_loader\"]) and not (\n",
    "        np.isnan(v[\"rot_angle_predicted\"]) and np.isnan(v[\"rot_angle_predicted_loader\"])\n",
    "    ):\n",
    "        print(\n",
    "            f\"File: {k}, predicted: {v['rot_angle_predicted']}, loader predicted: {v['rot_angle_predicted_loader']}\"\n",
    "        )\n",
    "\n",
    "# Check how many are correctly predicted\n",
    "correctly_predicted = sum(\n",
    "    [\n",
    "        1\n",
    "        for k, v in rot_angle_list.items()\n",
    "        if v[\"rot_angle_predicted\"] == v[\"actual_rotation\"]\n",
    "        or (np.isnan(v[\"rot_angle_predicted\"]) and np.isnan(v[\"actual_rotation\"]))\n",
    "    ]\n",
    ")\n",
    "print(f\"Correctly predicted: {correctly_predicted} out of {len(rot_angle_list)}\")\n",
    "for k, v in rot_angle_list.items():\n",
    "    if (v[\"rot_angle_predicted\"] != v[\"actual_rotation\"]) and not (\n",
    "        np.isnan(v[\"rot_angle_predicted\"]) and np.isnan(v[\"actual_rotation\"])\n",
    "    ):\n",
    "        print(\n",
    "            f\"File: {k}, predicted: {v['rot_angle_predicted']}, actual: {v['actual_rotation']}\"\n",
    "        )\n",
    "        if True:  # Print image\n",
    "            final_image = get_image_with_lines(v[\"image\"], v[\"lines\"])\n",
    "            final_image.show()\n",
    "            if v[\"filtered_lines\"] is not None and len(v[\"filtered_lines\"]) > 0:\n",
    "                filtered_image = get_image_with_lines(v[\"image\"], v[\"filtered_lines\"])\n",
    "                filtered_image.show()\n",
    "            else:\n",
    "                print(\"No filtered lines to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Test getting scale info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "records, data, loader = dataloader_wrapper(\n",
    "    list_of_paths=[data_training_path, data_vali_path, data_test_path],\n",
    "    test_settings=[False, False, True],\n",
    "    shuffle_settings=[True, False, False],\n",
    "    transform=None,\n",
    "    run_in_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect # TODO: Check why this is predicting too big grids sometimes\n",
    "threshold = 0.01  # In percent\n",
    "count_correct = 0\n",
    "count_total = 0\n",
    "deviation_x = []\n",
    "deviation_y = []\n",
    "for batch_idx, batch_dicts in enumerate(loader[0]):\n",
    "    for j in range(len(batch_dicts[\"image\"])):\n",
    "        pixels_per_grid_predicted = float(\n",
    "            batch_dicts[\"info_dict\"][\"pixels_per_grid_predicted\"][j]\n",
    "        )\n",
    "        x_grid = float(batch_dicts[\"info_dict\"][\"x_grid\"][j])\n",
    "        y_grid = float(batch_dicts[\"info_dict\"][\"y_grid\"][j])\n",
    "        sec_per_pixel_predicted = float(\n",
    "            batch_dicts[\"info_dict\"][\"sec_per_pixel_predicted\"][j]\n",
    "        )\n",
    "        mV_per_pixel_predicted = float(\n",
    "            batch_dicts[\"info_dict\"][\"mV_per_pixel_predicted\"][j]\n",
    "        )\n",
    "        sec_per_pixel = float(batch_dicts[\"info_dict\"][\"sec_per_pixel\"][j])\n",
    "        mV_per_pixel = float(batch_dicts[\"info_dict\"][\"mV_per_pixel\"][j])\n",
    "        deviation_x.append(abs(sec_per_pixel_predicted - sec_per_pixel) / sec_per_pixel)\n",
    "        deviation_y.append(abs(mV_per_pixel_predicted - mV_per_pixel) / mV_per_pixel)\n",
    "        if (abs(pixels_per_grid_predicted - x_grid) / x_grid > threshold) or (\n",
    "            abs(pixels_per_grid_predicted - y_grid) / y_grid > threshold\n",
    "        ):\n",
    "            print(\n",
    "                f\"File: {batch_dicts['info_dict']['image_path'][j]}, x_grid: {x_grid}, y_grid: {y_grid}, pixels_per_grid_predicted: {pixels_per_grid_predicted}\"\n",
    "            )\n",
    "            image_with_grid_lines = batch_dicts[\"image\"][j]\n",
    "            x_min = int(\n",
    "                IMAGES_PARTS_FOR_GRID_PREDICTION[0] * image_with_grid_lines.shape[2]\n",
    "            )\n",
    "            y_min = int(\n",
    "                IMAGES_PARTS_FOR_GRID_PREDICTION[1] * image_with_grid_lines.shape[1]\n",
    "            )\n",
    "            x_max = int(\n",
    "                IMAGES_PARTS_FOR_GRID_PREDICTION[2] * image_with_grid_lines.shape[2]\n",
    "            )\n",
    "            y_max = int(\n",
    "                IMAGES_PARTS_FOR_GRID_PREDICTION[3] * image_with_grid_lines.shape[1]\n",
    "            )\n",
    "            image_cropped_np = (\n",
    "                image_with_grid_lines.permute(1, 2, 0)\n",
    "                .numpy()\n",
    "                .astype(np.uint8)[y_min:y_max, x_min:x_max]\n",
    "            )\n",
    "            lines = get_lines(image_cropped_np, threshold_HoughLines=430)\n",
    "            lines_filtered = filter_lines(lines, degree_window=5, parallelism_count=1)\n",
    "            im_to_show = get_image_with_lines(image_cropped_np, lines_filtered)\n",
    "            im_to_show.show()\n",
    "        else:\n",
    "            count_correct += 1\n",
    "        count_total += 1\n",
    "print(f\"Correctly predicted: {count_correct} out of {count_total}\")\n",
    "print(\n",
    "    f\"Mean deviation sec_per_pixel: {round(np.nanmean(deviation_x),4)}, mean deviation mV_per_pixel: {round(np.nanmean(deviation_y),4)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Bounding box model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model and weights\n",
    "model_pretrained, preprocess = get_bbox_model(\n",
    "    \"FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "records, data, loader = dataloader_wrapper(\n",
    "    list_of_paths=[data_training_path, data_vali_path, data_test_path],\n",
    "    test_settings=[False, False, True],\n",
    "    shuffle_settings=[True, False, False],\n",
    "    transform=preprocess,\n",
    "    run_in_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate trainer\n",
    "params = [p for p in model_pretrained.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(\n",
    "    params, lr=LR_BBOX, momentum=MOMENTUM_BBOX, weight_decay=WEIGHT_DECAY_BBOX\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer, step_size=STEP_SIZE_BBOX, gamma=GAMMA_BBOX\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model_pretrained,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=lr_scheduler,\n",
    "    num_epochs=NUM_EPOCHS_BBOX,\n",
    "    device=DEVICE,\n",
    "    target_transform=get_bbox_type_targets,\n",
    "    input_transform=get_bbox_inputs,\n",
    "    model_dir=model_folder_checkpoints,\n",
    "    criterion=None,  # We will use the loss function from the model\n",
    "    run_in_parallel=RUN_IN_PARALLEL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "trained_model = trainer.fit(training_dataloader=loader[0], vali_dataloader=loader[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "save_torch_model(model_folder, trained_model, \"lead_bbox_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model, preprocess = get_bbox_model(box_score_thresh=0.01)\n",
    "finetuned_weights = torch.load(model_folder + \"lead_bbox_detection.pth\")\n",
    "model.load_state_dict(finetuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "records, data, loader = dataloader_wrapper(\n",
    "    list_of_paths=[data_training_path, data_vali_path, data_test_path],\n",
    "    test_settings=[False, False, True],\n",
    "    shuffle_settings=[True, False, False],\n",
    "    transform=preprocess,\n",
    "    run_in_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "image_paths = []\n",
    "outputs = []\n",
    "image_heights = []\n",
    "input_images = {}\n",
    "model.eval()\n",
    "test_loader = loader[1]  # Use vali_loader for now\n",
    "for i, batch_dict in enumerate(test_loader):\n",
    "    print(f\"Predicting batch {i + 1} of {len(test_loader)}\")\n",
    "    with torch.no_grad():\n",
    "        images = batch_dict[\"image\"]\n",
    "        batch_output = model(images)\n",
    "        for i in range(len(batch_output)):\n",
    "            image_path = batch_dict[\"info_dict\"][\"image_path\"][i]\n",
    "            image_paths.append(image_path)\n",
    "            outputs.append(batch_output[i])\n",
    "            image_heights.append(batch_dict[\"image\"][i].shape[1])\n",
    "            input_images[image_path] = batch_dict[\"image\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder and get the bbox with the highest score\n",
    "bbox_per_image = {}\n",
    "for image_path, output, image_height in zip(image_paths, outputs, image_heights):\n",
    "    bbox_per_image[image_path] = {}\n",
    "    bbox_per_image[image_path] = select_highest_scored_box(output)\n",
    "    bbox_per_image[image_path][\"image_height\"] = image_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "num_masks_to_plot = 5\n",
    "fig, ax = plt.subplots(num_masks_to_plot, 1, figsize=(10, 5 * num_masks_to_plot))\n",
    "i = 0\n",
    "for img_path in bbox_per_image.keys():\n",
    "    img = input_images[img_path]\n",
    "    img = (255.0 * (img - img.min()) / (img.max() - img.min())).to(torch.uint8)\n",
    "    img = img[:3, ...]\n",
    "\n",
    "    bboxes = {\n",
    "        k: v for k, v in bbox_per_image[image_path].items() if k != \"image_height\"\n",
    "    }\n",
    "\n",
    "    pred_boxes = torch.tensor(list(bboxes.values())).long()\n",
    "    pred_labels = [str(k) for k in bboxes.keys()]\n",
    "    colors = [\"red\"] * len(pred_labels)\n",
    "\n",
    "    output_image = draw_bounding_boxes(\n",
    "        img,\n",
    "        pred_boxes,\n",
    "        pred_labels,\n",
    "        colors=colors,\n",
    "        width=2,\n",
    "        font_size=40,\n",
    "        font=\"arial.ttf\",\n",
    "    )\n",
    "\n",
    "    ax[i].imshow(output_image.permute(1, 2, 0))\n",
    "    ax[i].set_title(os.path.basename(img_path))\n",
    "    i += 1\n",
    "    if i >= num_masks_to_plot:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to json format\n",
    "json_per_image = {}\n",
    "for image_path in bbox_per_image.keys():\n",
    "    json_per_image[image_path] = bbox_prediction_to_json(bbox_per_image[image_path])\n",
    "\n",
    "# Save all the jsons\n",
    "if False:\n",
    "    for image_path, json_content in json_per_image.items():\n",
    "        json_path = image_path.replace(\".png\", \".json\")\n",
    "        if os.path.exists(json_path):\n",
    "            with open(json_path, \"r\") as f:\n",
    "                existing_json_content = json.load(f)\n",
    "            existing_json_content.update(json_content)\n",
    "            json_content_to_store = existing_json_content\n",
    "        else:\n",
    "            json_content_to_store = json_content\n",
    "        json_object = json.dumps(json_content_to_store, indent=4)\n",
    "        with open(json_path, \"w\") as f:\n",
    "            f.write(json_object)\n",
    "else:\n",
    "    print(json_per_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lead level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "os.environ[\"nnUNet_raw\"] = NNUNET_RAW\n",
    "os.environ[\"nnUNet_preprocessed\"] = NNUNET_PREPROCESSED\n",
    "os.environ[\"nnUNet_results\"] = NNUNET_RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See README.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply single signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "! nnUNetv2_predict -d Dataset200_SingleSignals -i /data/wolf6245/data/ptb-xl/Dataset200_SingleSignals/imagesTv -o data/nnUNet_output/Dataset200_SingleSignals -f  0 -tr nnUNetTrainer -c 2d -p nnUNetPlans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess\n",
    "! nnUNetv2_apply_postprocessing -i data/nnUNet_output/Dataset200_SingleSignals -o data/nnUNet_output_pp/Dataset200_SingleSignals -pp_pkl_file data/nnUNet_results/Dataset200_SingleSignals/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0/postprocessing.pkl -np 8 -plans_json data/nnUNet_results/Dataset200_SingleSignals/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0/plans.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all masks and compare\n",
    "image_folder = f\"{ROOT}/data/ptb-xl/Dataset200_SingleSignals/imagesTv\"\n",
    "mask_folder = \"data/nnUNet_output_pp/Dataset200_SingleSignals\"\n",
    "masks = os.listdir(mask_folder)\n",
    "mask_names = [os.path.basename(mask_p) for mask_p in masks]\n",
    "image_paths = [\n",
    "    os.path.join(image_folder, mask_name.replace(\".png\", \"_0000.png\"))\n",
    "    for mask_name in mask_names\n",
    "]\n",
    "mask_paths = [os.path.join(mask_folder, mask_name) for mask_name in mask_names]\n",
    "image_mask_paths = list(zip(image_paths, mask_paths))\n",
    "random.shuffle(image_mask_paths)\n",
    "assert (\n",
    "    len(image_paths) == len(mask_paths) == len(image_mask_paths)\n",
    "), \"Number of images and masks do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "num_masks_to_plot = 5\n",
    "fig, ax = plt.subplots(num_masks_to_plot, 1, figsize=(10, 2 * num_masks_to_plot))\n",
    "i = 0\n",
    "for img_path, mask_path in image_mask_paths:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    example_img = read_image(img_path)\n",
    "    example_mask = read_image(mask_path)\n",
    "    ax[i] = plot_image(ax[i], example_img, example_mask)\n",
    "    ax[i].set_title(img_name)\n",
    "    i += 1\n",
    "    if i >= num_masks_to_plot:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply whole image version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "! nnUNetv2_predict -d Dataset300_FullImages -i /data/wolf6245/data/ptb-xl/Dataset300_FullImages/imagesTv -o data/nnUNet_output/Dataset300_FullImages -f  0 -tr nnUNetTrainer -c 2d -p nnUNetPlans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess\n",
    "! nnUNetv2_apply_postprocessing -i data/nnUNet_output/Dataset300_FullImages -o data/nnUNet_output_pp/Dataset300_FullImages -pp_pkl_file data/nnUNet_results/Dataset300_FullImages/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0/postprocessing.pkl -np 8 -plans_json data/nnUNet_results/Dataset300_FullImages/nnUNetTrainer__nnUNetPlans__2d/crossval_results_folds_0/plans.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all masks and compare\n",
    "image_folder = f\"{ROOT}/data/ptb-xl/Dataset300_FullImages/imagesTv\"\n",
    "mask_folder = \"data/nnUNet_output_pp/Dataset300_FullImages\"\n",
    "masks = os.listdir(mask_folder)\n",
    "mask_names = [os.path.basename(mask_p) for mask_p in masks]\n",
    "image_paths = [\n",
    "    os.path.join(image_folder, mask_name.replace(\".png\", \"_0000.png\"))\n",
    "    for mask_name in mask_names\n",
    "]\n",
    "mask_paths = [os.path.join(mask_folder, mask_name) for mask_name in mask_names]\n",
    "image_mask_paths = list(zip(image_paths, mask_paths))\n",
    "random.shuffle(image_mask_paths)\n",
    "assert (\n",
    "    len(image_paths) == len(mask_paths) == len(image_mask_paths)\n",
    "), \"Number of images and masks do not match\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "num_masks_to_plot = 50\n",
    "fig, ax = plt.subplots(num_masks_to_plot, 1, figsize=(10, 5 * num_masks_to_plot))\n",
    "i = 0\n",
    "for img_path, mask_path in image_mask_paths:\n",
    "    img_name = os.path.basename(img_path)\n",
    "    example_img = read_image(img_path)\n",
    "    example_mask = read_image(mask_path)\n",
    "    ax[i] = plot_image(ax[i], example_img, example_mask)\n",
    "    ax[i].set_title(img_name)\n",
    "    i += 1\n",
    "    if i >= num_masks_to_plot:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Vectorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "records, data, loader = dataloader_wrapper(\n",
    "    list_of_paths=[data_training_path, data_vali_path, data_test_path],\n",
    "    test_settings=[False, False, True],\n",
    "    shuffle_settings=[True, False, False],\n",
    "    transform=None,\n",
    "    single_signals=True,\n",
    "    run_in_parallel=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one example\n",
    "batch_dict = next(iter(loader[1]))\n",
    "\n",
    "# Get info for one image from batch\n",
    "j = 0\n",
    "\n",
    "# Get example\n",
    "image = batch_dict[\"image\"][j]\n",
    "mask = batch_dict[\"mask\"][j]\n",
    "\n",
    "# Get info\n",
    "image_path = batch_dict[\"info_dict\"][\"image_path\"][j]\n",
    "record_path = batch_dict[\"info_dict\"][\"signal_path\"][j]\n",
    "sec_per_pixel = batch_dict[\"info_dict\"][\"sec_per_pixel\"][j]\n",
    "mV_per_pixel = batch_dict[\"info_dict\"][\"mV_per_pixel\"][j]\n",
    "lead_name = batch_dict[\"info_dict\"][\"lead_name\"][j]\n",
    "original_size_image = (\n",
    "    batch_dict[\"info_dict\"][\"original_size_image\"][0][j].item(),\n",
    "    batch_dict[\"info_dict\"][\"original_size_image\"][1][j].item(),\n",
    "    batch_dict[\"info_dict\"][\"original_size_image\"][2][j].item(),\n",
    ")\n",
    "original_size_mask = (\n",
    "    batch_dict[\"info_dict\"][\"original_size_mask\"][0][j].item(),\n",
    "    batch_dict[\"info_dict\"][\"original_size_mask\"][1][j].item(),\n",
    "    batch_dict[\"info_dict\"][\"original_size_mask\"][2][j].item(),\n",
    ")\n",
    "\n",
    "# Re-resize the mask and image\n",
    "print(f\"Old image shape: {image.shape}, mask shape: {mask.shape}\")\n",
    "image = resize(image, (original_size_image[1], original_size_image[2]))\n",
    "mask = resize(mask, (original_size_mask[1], original_size_mask[2]))\n",
    "print(f\"Now image shape: {image.shape}, mask shape: {mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the mask and the image to positive mask area\n",
    "crop_to_mask = True\n",
    "if crop_to_mask:\n",
    "    image = cut_to_mask(image, mask)\n",
    "    mask = cut_to_mask(mask, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show masked image\n",
    "image_np = image.permute(1, 2, 0).numpy().astype(np.uint8)\n",
    "mask_np = mask[:1, :, :].squeeze().numpy().astype(np.uint8)\n",
    "masked_image = image_np\n",
    "masked_image[mask_np >= 1] = [0, 255, 0]\n",
    "plt.imshow(masked_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scaling info\n",
    "sec_per_box = sec_per_pixel * mask.shape[2]\n",
    "mV_per_box = mV_per_pixel * mask.shape[1]\n",
    "x_frequency = X_FREQUENCY\n",
    "total_seconds = round(sec_per_pixel.item() * mask.shape[2], 1)\n",
    "values_needed = int(total_seconds * x_frequency)\n",
    "\n",
    "# Get mask values\n",
    "non_zero_mean = torch.tensor(\n",
    "    [\n",
    "        torch.mean(torch.nonzero(mask[0, :, i]).type(torch.float32))\n",
    "        for i in range(mask.shape[2])\n",
    "    ]\n",
    ")\n",
    "\n",
    "# y-scale by shifting\n",
    "zero_pixel = mask.shape[1] / 2\n",
    "predicted_signal = (zero_pixel - non_zero_mean) * mV_per_pixel\n",
    "\n",
    "# x-scale by interpolation\n",
    "n = predicted_signal.shape[0]\n",
    "data_reshaped = predicted_signal.view(1, 1, n)\n",
    "resampled_data = F.interpolate(\n",
    "    data_reshaped, size=values_needed, mode=\"linear\", align_corners=False\n",
    ")\n",
    "predicted_signal_sampled = resampled_data.view(-1)\n",
    "print(\n",
    "    f\"Predicted signal length: {predicted_signal.shape[0]}, interpolated signal length: {predicted_signal_sampled.shape[0]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the original signal\n",
    "print(f\"Using signal from {record_path} with lead {lead_name} from image {image_path}\")\n",
    "label_signal, label_fields = load_signals(record_path)\n",
    "mask_signal = reorder_signal(label_signal, label_fields[\"sig_name\"], [lead_name])\n",
    "\n",
    "# Remove nan values from the signal\n",
    "original_signal = torch.tensor(mask_signal[:, 0])\n",
    "original_signal = original_signal[~torch.isnan(original_signal)]\n",
    "print(\n",
    "    f\"Original signal length: {len(mask_signal)}, after removing nan values: {len(original_signal)}\"\n",
    ")\n",
    "\n",
    "# Calc difference between corrected and original signal\n",
    "difference_signal = predicted_signal_sampled - original_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the signal, the original and the difference\n",
    "y_min = -0.6\n",
    "y_max = 0.6\n",
    "fig, ax = plt.subplots(1, 5, figsize=(30, 5))\n",
    "ax[0].plot(original_signal)\n",
    "ax[0].set_ylim(y_min, y_max)\n",
    "ax[0].set_title(\"Original signal\")\n",
    "ax[1].plot(predicted_signal)\n",
    "ax[1].set_ylim(y_min, y_max)\n",
    "ax[1].set_title(\"Predicted signal not sampled\")\n",
    "ax[2].plot(predicted_signal_sampled)\n",
    "ax[2].set_ylim(y_min, y_max)\n",
    "ax[2].set_title(\"Predicted signal sampled\")\n",
    "ax[3].plot(original_signal)\n",
    "ax[3].plot(predicted_signal_sampled)\n",
    "ax[3].set_ylim(y_min, y_max)\n",
    "ax[3].legend([\"Original\", \"Predicted sampled\"])\n",
    "ax[3].set_title(\"Original and predicted sampled signal\")\n",
    "ax[4].plot(difference_signal)\n",
    "ax[4].set_ylim(y_min, y_max)\n",
    "ax[4].set_title(\"Difference signal\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. run_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we simulate the model inference on a single record."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prep from run_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from run_model import *\n",
    "from team_code import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type\n",
    "binary_signal_masks = False\n",
    "\n",
    "# Settings to test\n",
    "use_true_rot = False\n",
    "use_true_scale = True\n",
    "use_true_bbox = True\n",
    "use_true_mask = False\n",
    "\n",
    "# Print settings\n",
    "verbose = True\n",
    "\n",
    "# If we want to crop to mask\n",
    "crop_to_mask = False\n",
    "\n",
    "# If nans should be interpolated\n",
    "interpolate_nans = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Args\n",
    "args = argparse.ArgumentParser()\n",
    "args.model_folder = \"model\"\n",
    "args.output_folder = \"data/test_outputs\"\n",
    "\n",
    "if binary_signal_masks:\n",
    "    args.data_folder = f\"{ROOT}/data/ptb-xl/Dataset400_BinarySignals/imagesTs\"\n",
    "else:\n",
    "    args.data_folder = f\"{ROOT}/data/ptb-xl/Dataset500_Signals/imagesTs_original\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep\n",
    "digitization_model, classification_model = load_models(args.model_folder, True)\n",
    "records = find_records(args.data_folder)\n",
    "num_records = len(records)\n",
    "os.makedirs(args.output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate one record from loop\n",
    "i = 2  # Record: Select one record\n",
    "j = 1  # Image: Select first image, but there should also only be one per signal\n",
    "data_record = os.path.join(args.data_folder, records[i])\n",
    "output_record = os.path.join(args.output_folder, records[i])\n",
    "if verbose:\n",
    "    print(f\"Using record {data_record}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 run_models(data_record, digitization_model, classification_model, args.verbose) -> signals, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert\n",
    "record = data_record\n",
    "digitization_model = digitization_model\n",
    "classification_model = classification_model\n",
    "header_file = get_header_file(record)\n",
    "header = load_text(header_file)\n",
    "num_samples = get_num_samples(header)\n",
    "num_signals = get_num_signals(header)\n",
    "signal_names = get_signal_names(header)\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "path = os.path.split(record)[0]\n",
    "image_files = get_image_files(record)\n",
    "image_file = image_files[j]\n",
    "image_file_path = os.path.join(path, image_file)\n",
    "image = read_image(image_file_path)\n",
    "image = image[:3]\n",
    "if verbose:\n",
    "    print(f\"Using image {image_file_path}\")\n",
    "    plt.imshow(image.permute(1, 2, 0).numpy())\n",
    "\n",
    "# Only for testing, load the json\n",
    "if any([use_true_rot, use_true_scale, use_true_bbox, use_true_mask]):\n",
    "    label_signal, label_fields = load_signals(record)\n",
    "    json_dict, _ = load_json(record)\n",
    "    json_dict = json_dict[j]\n",
    "    mask_file_path = image_file_path.replace(\"/imagesT\", \"/labelsT\").replace(\"_0000.png\", \".png\").replace('_original', '')\n",
    "    mask = read_image(mask_file_path)\n",
    "    if verbose:\n",
    "        print(\"Loaded json and mask.\")\n",
    "        print(\"Mask distribution:\")\n",
    "        print(pd.Series(mask.numpy().flatten()).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate\n",
    "if use_true_rot:\n",
    "    rot_angle = json_dict[\"rotate\"]\n",
    "    if verbose:\n",
    "        print(f\"Using true rotation angle: {rot_angle}\")\n",
    "else:\n",
    "    rot_angle = get_rotation_angle(image.permute(1, 2, 0).numpy().astype(np.uint8))\n",
    "    if verbose:\n",
    "        print(f\"Using predicted rotation angle: {rot_angle}\")\n",
    "\n",
    "image_rotated = rotate(image, rot_angle)\n",
    "if verbose:\n",
    "    plt.imshow(image_rotated.permute(1, 2, 0).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTION 1: Bounding boxes and individual signal segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary_signal_masks:\n",
    "    # Get bounding box\n",
    "    if use_true_bbox:\n",
    "        lead_bounding_box = json_dict[\"lead_bounding_box\"]\n",
    "        lead_bounding_box_filtered = filter_for_full_lead(\n",
    "            lead_bounding_box,\n",
    "            json_dict[\"full_mode_lead\"][\"val\"],\n",
    "            box_type=\"lead_bounding_box\",\n",
    "            image_path=image_file,\n",
    "        )\n",
    "        if verbose:\n",
    "            print(\"Using true bboxes\")\n",
    "            print(\n",
    "                f\"Found boxes for {[b['lead_name'] for b in lead_bounding_box_filtered]}\"\n",
    "            )\n",
    "    else:\n",
    "        # Predict\n",
    "        model = digitization_model[\"bbox_model\"][\"model\"]\n",
    "        transform = digitization_model[\"bbox_model\"][\"preprocess\"]\n",
    "        model.eval()\n",
    "        image_rotated_transformed = transform(image_rotated)\n",
    "        with torch.no_grad():\n",
    "            batch_output = model([image_rotated_transformed])\n",
    "            output = batch_output[0]\n",
    "            image_height = image_rotated.shape[1]\n",
    "\n",
    "        # Reorder and get the bbox with the highest score\n",
    "        bbox = select_highest_scored_box(output)\n",
    "        bbox = convert_box_to_integer(bbox)\n",
    "        bbox[\"image_height\"] = image_height\n",
    "        lead_bounding_box_filtered = bbox_prediction_to_json(bbox)\n",
    "        lead_bounding_box_filtered = lead_bounding_box_filtered[\n",
    "            \"lead_bounding_box_predicted\"\n",
    "        ]\n",
    "\n",
    "        if verbose:\n",
    "            print(\n",
    "                f\"Using predicted bboxes. Found boxes for {[b['lead_name'] for b in lead_bounding_box_filtered]}\"\n",
    "            )\n",
    "\n",
    "    if verbose:\n",
    "        dict_test = {\n",
    "            \"image\": image_rotated,\n",
    "            \"info_dict\": {\n",
    "                \"lead_bounding_box\": lead_bounding_box_filtered,\n",
    "                \"full_mode_lead\": json_dict[\"full_mode_lead\"][\"val\"],\n",
    "                \"image_path\": image_file_path,\n",
    "            },\n",
    "        }\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "        ax = plot_image_with_torch(ax, dict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if binary_signal_masks:\n",
    "    # Segment\n",
    "    # Split images\n",
    "    signal_images = {}\n",
    "    signal_positions = {}\n",
    "    for box in lead_bounding_box_filtered:\n",
    "        signal_img, y1 = cut_image_to_bbox(image_rotated, box, True)\n",
    "        signal_positions[box[\"lead_name\"]] = y1\n",
    "        signal_images[box[\"lead_name\"]] = signal_img\n",
    "    if verbose:\n",
    "        print(f\"Split images for {signal_images.keys()}\")\n",
    "\n",
    "    # Run segmentation\n",
    "    signal_masks = {}\n",
    "    if use_true_mask:\n",
    "        for box in lead_bounding_box_filtered:\n",
    "            signal_mask = cut_image_to_bbox(mask, box)\n",
    "            signal_masks[box[\"lead_name\"]] = signal_mask\n",
    "        if verbose:\n",
    "            print(\"Using true masks.\")\n",
    "    else:\n",
    "        for lead, img in signal_images.items():  # TODO: Parallelise this\n",
    "            image_rotated_resized = resize(img, IMG_SIZE)\n",
    "            signal_mask_predicted_resized = predict_mask_nnunet(\n",
    "                image_rotated_resized, \"Dataset200_SingleSignals\"\n",
    "            )\n",
    "            signal_mask_predicted = resize(\n",
    "                signal_mask_predicted_resized, (img.shape[1], img.shape[2])\n",
    "            )\n",
    "            signal_masks[lead] = signal_mask_predicted\n",
    "        if verbose:\n",
    "            print(\"Using predicted masks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OPTION 2: Direct signal segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment\n",
    "if not binary_signal_masks:\n",
    "    if use_true_mask:\n",
    "        if verbose:\n",
    "            print(\"Using true, multiclass masks.\")\n",
    "        mask_to_use = mask\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"Using predicted, multiclass masks.\")\n",
    "        mask_to_use = predict_mask_nnunet(\n",
    "            image_rotated, f\"Dataset{X_FREQUENCY}_Signals\"\n",
    "        )\n",
    "\n",
    "    # Use mask to cut into single, binary masks\n",
    "    signal_masks, signal_positions, signal_images = cut_binary(mask_to_use, image_rotated, signal_names)\n",
    "    if verbose:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "        ax = plot_image(ax, image_rotated, mask_to_use)\n",
    "        ax.set_title(image_file_path)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crop to mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop the mask and the image to positive mask area\n",
    "signal_images_cropped = {}\n",
    "signal_masks_cropped = {}\n",
    "signal_positions_cropped = {}\n",
    "if (\n",
    "    crop_to_mask\n",
    "):  # TODO: What to do if mask misses values at the beginning or at the end?\n",
    "    for lead in signal_images.keys():\n",
    "        signal_images_cropped[lead], y1 = cut_to_mask(\n",
    "            signal_images[lead], signal_masks[lead], True\n",
    "        )\n",
    "        signal_masks_cropped[lead] = cut_to_mask(signal_masks[lead], signal_masks[lead])\n",
    "        signal_positions_cropped[lead] = signal_positions[lead] + y1\n",
    "else:\n",
    "    signal_images_cropped = signal_images\n",
    "    signal_masks_cropped = signal_masks\n",
    "    signal_positions_cropped = signal_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scaling info\n",
    "if use_true_scale:\n",
    "    x_grid = json_dict[\"x_grid\"]\n",
    "    y_grid = json_dict[\"y_grid\"]\n",
    "    mm_per_pixel_x = get_mm_per_pixel(x_grid)\n",
    "    mm_per_pixel_y = get_mm_per_pixel(y_grid)\n",
    "    sec_per_pixel = get_sec_per_pixel(mm_per_pixel_x)\n",
    "    mV_per_pixel = get_mV_per_pixel(mm_per_pixel_y)\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Using true scaling info: x_grid: {x_grid}, y_grid: {y_grid}, sec_per_pixel: {round(sec_per_pixel,4)}, mV_per_pixel: {round(mV_per_pixel,4)}\"\n",
    "        )\n",
    "else:\n",
    "    pixels_per_grid, sec_per_pixel, mV_per_pixel = get_grid_info(image_rotated)\n",
    "    x_grid = pixels_per_grid\n",
    "    y_grid = pixels_per_grid\n",
    "    if verbose:\n",
    "        print(\n",
    "            f\"Predicted scaling info: {x_grid}, y_grid: {y_grid}, sec_per_pixel: {round(sec_per_pixel,4)}, mV_per_pixel: {round(mV_per_pixel,4)}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print\n",
    "if verbose:\n",
    "    print(f\"Plotting image and masks.\")\n",
    "    example_img_masked_dict = {}\n",
    "    fig, ax = plt.subplots(\n",
    "        len(signal_images_cropped), 1, figsize=(10, 2 * len(signal_images_cropped))\n",
    "    )\n",
    "    for i, l in enumerate(signal_images_cropped.keys()):\n",
    "        example_img = signal_images_cropped[l]\n",
    "        example_mask = signal_masks_cropped[l]\n",
    "        if isinstance(example_img, torch.Tensor):\n",
    "            example_img = example_img.permute(1, 2, 0).numpy().astype(np.uint8)\n",
    "        if isinstance(example_mask, torch.Tensor):\n",
    "            example_mask = example_mask[:1, :, :].squeeze().numpy().astype(np.uint8)\n",
    "        example_img_masked = example_img\n",
    "        example_img_masked[example_mask >= 1] = [0, 255, 0]\n",
    "        example_img_masked_dict[l] = example_img_masked\n",
    "        if verbose:\n",
    "            ax[i].imshow(example_img_masked)\n",
    "            ax[i].set_title(l)\n",
    "    print(\"Mask distribution of example mask for lead II:\")\n",
    "    print(pd.Series(signal_masks_cropped[\"II\"].numpy().flatten()).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorise\n",
    "signals_predicted = {}\n",
    "for lead, mask in signal_masks_cropped.items():\n",
    "    signals_predicted[lead] = vectorise(\n",
    "        image_rotated, \n",
    "        mask, \n",
    "        signal_positions_cropped[lead], \n",
    "        sec_per_pixel, \n",
    "        mV_per_pixel, \n",
    "        Y_VALUES_PER_LEAD[\"full\"], \n",
    "        Y_VALUES_PER_LEAD[lead], \n",
    "        num_samples,\n",
    "        interpolate_nans=interpolate_nans\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "if verbose and any([use_true_rot, use_true_scale, use_true_bbox, use_true_mask]):\n",
    "    fig, ax = plt.subplots(\n",
    "        len(signals_predicted), 3, figsize=(18, 4 * len(signals_predicted))\n",
    "    )\n",
    "    snr = []\n",
    "    for i, (lead_name, predicted_signal_sampled) in enumerate(\n",
    "        signals_predicted.items()\n",
    "    ):\n",
    "        # Get data\n",
    "        mask_signal = reorder_signal(\n",
    "            label_signal, label_fields[\"sig_name\"], [lead_name]\n",
    "        )\n",
    "        original_signal = torch.tensor(mask_signal[:, 0])\n",
    "        original_signal = original_signal[~torch.isnan(original_signal)]\n",
    "\n",
    "        # Calc difference\n",
    "        if len(original_signal) == len(predicted_signal_sampled):\n",
    "            difference = predicted_signal_sampled - original_signal\n",
    "            signal_snr = compute_snr(\n",
    "                original_signal, predicted_signal_sampled\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Lengths of original and predicted signal do not match.\")\n",
    "\n",
    "        # Plot\n",
    "        masked_img = example_img_masked_dict[lead_name]\n",
    "        snr.append(signal_snr)\n",
    "        ax[i, 0].plot(original_signal)\n",
    "        ax[i, 0].plot(predicted_signal_sampled)\n",
    "        ax[i, 0].legend([\"Original\", \"Predicted\"])\n",
    "        ax[i, 0].set_title(f\"{lead_name}: Original and predicted signal\")\n",
    "        ax[i, 1].imshow(masked_img)\n",
    "        ax[i, 1].set_title(f\"{lead_name}: Masked image\")\n",
    "        ax[i, 2].plot(difference)\n",
    "        ax[i, 2].set_title(\n",
    "            f\"{lead_name}: Difference signal (SNR: {round(signal_snr,2)})\"\n",
    "        )\n",
    "    fig.suptitle(f\"Average SNR: {round(np.mean(snr),2)}\")\n",
    "    fig.tight_layout(pad=4.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correct window\n",
    "signal_list = []\n",
    "for signal_name in signal_names:\n",
    "    signal = signals_predicted[signal_name].numpy()\n",
    "    if len(signal) < num_samples:\n",
    "        nan_signal = np.empty(num_samples)\n",
    "        nan_signal[:] = np.nan\n",
    "        signal_start = SIGNAL_START[signal_name] * num_samples/10\n",
    "        nan_signal[int(signal_start):int(signal_start + len(signal))] = signal\n",
    "        signal_list.append(nan_signal)\n",
    "    else:\n",
    "        signal_list.append(signal)\n",
    "        \n",
    "# Transpose\n",
    "signal = np.array(signal_list).T\n",
    "\n",
    "if verbose:\n",
    "    print(f\"Signal shape: {signal.shape} (should be (5000, 12))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep labels\n",
    "model = classification_model[\"model\"]\n",
    "classes = classification_model[\"classes\"]\n",
    "features = extract_features(record)\n",
    "features = features.reshape(1, -1)\n",
    "probabilities = model.predict_proba(features)\n",
    "probabilities = np.asarray(probabilities, dtype=np.float32)[:, 0, 1]\n",
    "max_probability = np.nanmax(probabilities)\n",
    "labels = [\n",
    "    classes[i]\n",
    "    for i, probability in enumerate(probabilities)\n",
    "    if probability == max_probability\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "signals = signal\n",
    "output_path = os.path.split(output_record)[0]\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "data_header = load_header(data_record)\n",
    "save_header(output_record, data_header)\n",
    "comments = [l for l in data_header.split(\"\\n\") if l.startswith(\"#\")]\n",
    "save_signals(output_record, signals, comments)\n",
    "save_labels(output_record, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Check if correctly saved for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "input_record = data_record\n",
    "print(f\"Comparing {input_record} and {output_record}\")\n",
    "\n",
    "# Load the signals\n",
    "input_signal, input_fields = load_signals(input_record)\n",
    "input_channels = input_fields[\"sig_name\"]\n",
    "input_num_samples = input_fields[\"sig_len\"]\n",
    "output_signal, output_fields = load_signals(output_record)\n",
    "output_channels = output_fields[\"sig_name\"]\n",
    "channels = input_channels\n",
    "\n",
    "# Reorder\n",
    "output_signal = reorder_signal(output_signal, output_channels, input_channels)\n",
    "\n",
    "# Trim official\n",
    "output_signal_trimmed = trim_signal(output_signal, input_num_samples)\n",
    "\n",
    "# Replace nan with 0\n",
    "output_signal_trimmed[np.isnan(output_signal_trimmed)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate snr\n",
    "snr = []\n",
    "for j, channel in enumerate(channels):\n",
    "\n",
    "    value = compute_snr(input_signal[:, j], output_signal_trimmed[:, j])\n",
    "    snr.append(value)\n",
    "\n",
    "mean_snr = np.nanmean(snr)\n",
    "print(f\"Mean SNR: {mean_snr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(len(channels), 2, figsize=(12, 4 * len(channels)))\n",
    "for j, channel in enumerate(channels):\n",
    "    ax[j, 0].plot(input_signal[:, j])\n",
    "    ax[j, 0].plot(output_signal_trimmed[:, j])\n",
    "    ax[j, 0].set_xlim(0, 5000)\n",
    "    ax[j, 0].legend([\"Original\", \"Predicted\"])\n",
    "    ax[j, 0].set_title(f\"{channel}: Original and predicted signal\")\n",
    "\n",
    "    ax[j, 1].plot(input_signal[:, j] - output_signal_trimmed[:, j])\n",
    "    ax[j, 1].set_xlim(0, 5000)\n",
    "    ax[j, 1].set_title(f\"{channel}: Difference signal (SNR: {round(snr[j],2)})\")\n",
    "\n",
    "fig.suptitle(\n",
    "    f\"Record: {os.path.split(data_record)[1]}, Average SNR: {round(mean_snr,2)}\"\n",
    ")\n",
    "fig.tight_layout(pad=4.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep\n",
    "args = argparse.ArgumentParser()\n",
    "args.input_folder = f\"data/test_inputs\"\n",
    "args.output_folder = \"data/test_outputs\"\n",
    "args.score_file = \"data/evaluation/scores.csv\"\n",
    "args.extra_scores = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute scores and unpack them\n",
    "scores = evaluate_model(args.input_folder, args.output_folder, args.extra_scores)\n",
    "(\n",
    "    snr,\n",
    "    snr_median,\n",
    "    ks_metric,\n",
    "    asci_metric,\n",
    "    mean_weighted_absolute_difference_metric,\n",
    "    f_measure,\n",
    ") = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert\n",
    "(\n",
    "    snr,\n",
    "    snr_median,\n",
    "    ks_metric,\n",
    "    asci_metric,\n",
    "    mean_weighted_absolute_difference_metric,\n",
    "    f_measure,\n",
    ") = scores\n",
    "output_string = f\"SNR: {snr:.3f}\\n\" + f\"F-measure: {f_measure:.3f}\\n\"\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "if args.score_file:\n",
    "    score_folder = os.path.split(args.score_file)[0]\n",
    "    os.makedirs(score_folder, exist_ok=True)\n",
    "    save_text(args.score_file, output_string)\n",
    "else:\n",
    "    print(output_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "physionet24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
